
import pandas as pd

def analyze_metrics_consent(row, result_df):
    acc_name = row['acc_name']
    relevant_titles = [
        'Consent Approved Email Opt-In',
        'Consent Approved Email Opt-Out',
        'Consent Marketing Email Opt-In',
        'Consent Marketing Email Opt-Out'
    ]
    
    counts = {
        'Consent Approved Email Opt-In': 0,
        'Consent Approved Email Opt-Out': 0,
        'Consent Marketing Email Opt-In': 0,
        'Consent Marketing Email Opt-Out': 0
    }
    
    # Filter result_df for the given account and relevant titles
    filtered_df = result_df[(result_df['acc_name'] == acc_name) & (result_df['int_title'].isin(relevant_titles))]
    
    # Calculate counts
    title_counts = filtered_df.groupby('int_title')['int_title_count'].sum().to_dict()
    
    for title in relevant_titles:
        if title in title_counts:
            counts[title] = title_counts[title]
    
    return counts

# Example loop to append results to newrows
newrows = []
for idx, row in result_df.iterrows():
    for type_ in ['Consents']:
        if type_ == 'Consents':
            finding = analyze_metrics_consent(row, result_df)
            # Append the new row to the new DataFrame
            newrows.append({
                'Date': '1.12.2023',  # Assuming the date is the same as in the example
                'Freq': 'Month',  # Assuming the frequency is the same
                'Time Desc': 'Covering changes in November data to December data',  # Placeholder description
                'Type': type_,
                'Account': row['acc_name'],
                'Brand': '',  # Assuming brand_name is not provided in the row
                'Finding': finding
            })

# Convert newrows to a DataFrame and display it
new_df = pd.DataFrame(newrows)
import ace_tools as tools; tools.display_dataframe_to_user(name="Consent Metrics", dataframe=new_df)













import pandas as pd
from datetime import datetime, timedelta

# Function to get AE and ME counts gained and lost in the last 3 months using result_df
def get_ae_me_counts(result_df, end_date, months=3):
    # Define the date range (last 3 months from end_date)
    start_date = end_date - timedelta(days=months*30)

    # Filter the data for the last 3 months
    filtered_df = result_df[(result_df['cases_date'] >= start_date) & (result_df['cases_date'] <= end_date)]

    # Initialize counts
    ae_gained = 0
    me_gained = 0
    ae_lost = 0
    me_lost = 0

    # Get unique 'pk_mdm_key' counts for each 'acc_name' and 'int_title'
    current_counts = filtered_df.groupby(['acc_name', 'int_title'])['pk_mdm_key'].nunique().reset_index()
    current_counts.columns = ['acc_name', 'int_title', 'current_count']

    # Filter data for the previous 3 months
    previous_start_date = start_date - timedelta(days=months*30)
    previous_end_date = start_date
    previous_df = result_df[(result_df['cases_date'] >= previous_start_date) & (result_df['cases_date'] <= previous_end_date)]
    
    previous_counts = previous_df.groupby(['acc_name', 'int_title'])['pk_mdm_key'].nunique().reset_index()
    previous_counts.columns = ['acc_name', 'int_title', 'previous_count']

    # Merge current and previous counts
    counts_df = pd.merge(current_counts, previous_counts, on=['acc_name', 'int_title'], how='outer').fillna(0)
    
    # Calculate gains and losses
    for index, row in counts_df.iterrows():
        if 'Approved Email' in row['int_title']:
            if row['current_count'] > row['previous_count']:
                ae_gained += row['current_count'] - row['previous_count']
            elif row['current_count'] < row['previous_count']:
                ae_lost += row['previous_count'] - row['current_count']
        elif 'Marketing Email' in row['int_title']:
            if row['current_count'] > row['previous_count']:
                me_gained += row['current_count'] - row['previous_count']
            elif row['current_count'] < row['previous_count']:
                me_lost += row['previous_count'] - row['current_count']

    return ae_gained, me_gained, ae_lost, me_lost

# Assuming result_df is already defined and available

# Define the end date
end_date = datetime(2023, 12, 31)

# Get the counts
ae_gained, me_gained, ae_lost, me_lost = get_ae_me_counts(result_df, end_date)

# Display the results
print(f"AE counts gained: {ae_gained}")
print(f"ME counts gained: {me_gained}")
print(f"AE counts lost: {ae_lost}")
print(f"ME counts lost: {me_lost}")


































import pandas as pd
from datetime import datetime, timedelta

# Load the dataset
file_path = '/mnt/data/your_dataset_file.xlsx'
df = pd.read_excel(file_path)

# Convert 'cases_date' to datetime
df['cases_date'] = pd.to_datetime(df['cases_date'], format='%m/%d/%Y')

# Define the date range (last 3 months from December 31, 2023)
end_date = datetime(2023, 12, 31)
start_date = end_date - timedelta(days=90)

# Filter the data for the last 3 months
filtered_df = df[(df['cases_date'] >= start_date) & (df['cases_date'] <= end_date)]

# Count unique 'pk_mdm_key' records for each 'acc_name'
unique_mdm_counts = filtered_df.groupby('acc_name')['pk_mdm_key'].nunique().reset_index()
unique_mdm_counts.columns = ['acc_name', 'unique_mdm_count']

# Get 'int_title' date counts in each category
int_title_counts = filtered_df.groupby(['acc_name', 'int_title']).size().reset_index(name='int_title_count')

# Merge the two dataframes to have both unique counts and int_title counts
result_df = unique_mdm_counts.merge(int_title_counts, on='acc_name', how='left')

# Display the result
import ace_tools as tools; tools.display_dataframe_to_user(name="Filtered Consent Data", dataframe=result_df)







def analyse_finding_consents(row):
    # Example analysis logic for consents based on F2F call dates
    findings = []
    if pd.notnull(row.get('NextF2Fcall_dec23')):
        findings.append(f"Next call in {row['NextF2Fcall_dec23']} days")
    if pd.notnull(row.get('LastF2Fcall_dec23')):
        findings.append(f"Last call was {row['LastF2Fcall_dec23']} days ago")
    return "; ".join(findings) if findings else "No F2F call information available."


import pandas as pd

# Assuming df_dec is your original December DataFrame
# df_dec = pd.read_csv('your_december_data.csv')  # Load your data

# Define the columns based on the given image
columns = ['Date', 'Freq', 'Time Desc', 'Type', 'Account', 'Brand', 'Finding']

# Initialize the new DataFrame
df_new = pd.DataFrame(columns=columns)

# Populate the new DataFrame
for idx, row in df_dec.iterrows():
    for type_ in ['Sales', 'Interaction', 'Consents']:
        if type_ == 'Sales':
            finding = analyse_finding_sales(row)
        elif type_ == 'Interaction':
            finding = analyse_finding_interaction(row)
        elif type_ == 'Consents':
            finding = analyse_finding_consents(row)
        
        # Append the new row to the new DataFrame
        df_new = df_new.append({
            'Date': '1.12.2023',  # Assuming the date is the same as in the example
            'Freq': 'Month',  # Assuming the frequency is the same
            'Time Desc': 'Covering changes in October data to November data',  # Placeholder description
            'Type': type_,
            'Account': row['acc_name'],
            'Brand': row['brand_name'],
            'Finding': finding
        }, ignore_index=True)

# Display the new DataFrame
print(df_new)






import pandas as pd

# Assuming df_dec is your original December DataFrame
# df_dec = pd.read_csv('your_december_data.csv')  # Load your data

# Define the columns based on the given image
columns = ['Date', 'Freq', 'Time Desc', 'Type', 'Account', 'Brand', 'Finding']

# Initialize the new DataFrame
df_new = pd.DataFrame(columns=columns)

# Populate the new DataFrame
for idx, row in df_dec.iterrows():
    if row['Type'] == 'Sales':
        finding = analyse_finding_sales(row)
    elif row['Type'] == 'Interaction':
        finding = analyse_finding_interaction(row)
    elif 'Consents' in row['Type']:
        finding = analyse_finding_consents(row)
    else:
        finding = "No specific finding."

    # Append the new row to the new DataFrame
    df_new = df_new.append({
        'Date': '1.12.2023',  # Assuming the date is the same as in the example
        'Freq': 'Month',  # Assuming the frequency is the same
        'Time Desc': 'Covering changes in October data to November data',  # Placeholder description
        'Type': row['Type'],
        'Account': row['Account'],
        'Brand': row['Brand'],
        'Finding': finding
    }, ignore_index=True)

# Display the new DataFrame
print(df_new)


















Step 1: Data Extraction from SQL Tables
Objective: Extract raw data from SQL tables related to sales, interactions, and consent.

Details:

Identify relevant SQL tables and columns.
Write SQL queries to extract the necessary data.
Combine and clean the data, ensuring only relevant columns are included.
Store the extracted data in a combined SQL table for ease of further processing.

Step 2: Data Preparation and Export
Objective: Prepare the combined data for further analysis.

Details:

Ensure data integrity and handle missing values.
Export the combined data as a CSV file.

Step 3: Complex Computation and Analysis
Objective: Perform complex computations for each period and prepare the data for GPT analysis.

Details:

Read the CSV file into a DataFrame.
Perform any required computations (e.g., growth rates, trend analysis).

Step 4: Generate Insights Using GPT
Objective: Use GPT to generate detailed insights for sales, interactions, and consent data.

Details:

Define prompts for GPT to generate insights.
Iterate through each account and generate insights.
Store insights in a DataFrame.

Step 5: Building a Knowledge Base
Objective: Store and organize the generated insights in a knowledge base for easy access and retrieval.

Details:

Organize insights by customer and category.
Store insights in a database or knowledge management system.
Provide interfaces for querying and retrieving insights.


Summary
Data Extraction from SQL Tables: Extract relevant data from SQL tables and combine them into a single table.
Data Preparation and Export: Prepare the combined data and export it as a CSV file.
Complex Computation and Analysis: Perform required computations and prepare the data for GPT analysis.
Generate Insights Using GPT: Use GPT to generate detailed insights for sales, interactions, and consent data.
Building a Knowledge Base: Store and organize the generated insights in a knowledge base for easy access and retrieval.














sales_columns = [
    'sales_dec2023', 'DeltaRollingQuarterPreviousYearChange', 'DeltaMATChangePY',
    'PreviousYearChange_dec2023', 'RollingQuarter_dec2023', 'MAT_dec2023'
]
interaction_columns = [
    'total_interactions_MATQ_growth', 'total_interactions_ROLQ_growth',
    'EVENTS - Veeva_MATQ_growth', 'CALLS - Veeva_MATQ_growth', 
    'AE - Veeva_MATQ_growth', 'SFMC Marketing Email_MATQ_growth'
]
consent_columns = [
    'Consent Approved Email Opt-In', 'Consent Approved Email Opt-Out',
    'Consent Marketing Email Opt-In', 'Consent Marketing Email Opt-Out',
    'Consent Postal Opt-In', 'Consent Postal Opt-Out',
    'Consent Phone Opt-In', 'Consent Phone Opt-Out'
]

# Define prompt templates with column descriptions
sales_prompt_template = """
You are an expert in providing detailed insights.
Our dataset is related to the healthcare industry and contains sales data.
Given a customer with the following sales details:

Customer Name: {customer_name}
Sales Data: 
{sales}

Sales Data Descriptions:
sales_dec2023: Total sales for the month of December 2023.
DeltaRollingQuarterPreviousYearChange: Change in rolling quarter sales compared to the previous year.
DeltaMATChangePY: Change in Moving Annual Total (MAT) sales compared to the previous year.
PreviousYearChange_dec2023: Change in sales compared to December 2022.
RollingQuarter_dec2023: Sales for the rolling quarter ending in December 2023.
MAT_dec2023: Moving Annual Total (MAT) sales for the year ending in December 2023.

Generate a detailed insight report for this customer focusing on sales trends and any significant changes.
"""

interaction_prompt_template = """
You are an expert in providing detailed insights.
Our dataset is related to the healthcare industry and contains interaction data.
Given a customer with the following interaction details:

Customer Name: {customer_name}
Interaction Data: 
{interactions}

Interaction Data Descriptions:
total_interactions_MATQ_growth: Total interactions growth for the Moving Annual Total (MAT) quarter.
total_interactions_ROLQ_growth: Total interactions growth for the Rolling Quarter (ROLQ).
EVENTS - Veeva_MATQ_growth: Growth in Veeva events for MAT quarter.
CALLS - Veeva_MATQ_growth: Growth in Veeva calls for MAT quarter.
AE - Veeva_MATQ_growth: Growth in Veeva account executive interactions for MAT quarter.
SFMC Marketing Email_MATQ_growth: Growth in Salesforce Marketing Cloud email interactions for MAT quarter.

Generate a detailed insight report for this customer focusing on interaction trends and their impact on sales.
"""

consent_prompt_template = """
You are an expert in providing detailed insights.
Our dataset is related to the healthcare industry and contains consent data.
Given a customer with the following consent details:

Customer Name: {customer_name}
Consent Data: 
{consent}

Consent Data Descriptions:
Consent Approved Email Opt-In: Date of consent for approved email opt-in.
Consent Approved Email Opt-Out: Date of consent for approved email opt-out.
Consent Marketing Email Opt-In: Date of consent for marketing email opt-in.
Consent Marketing Email Opt-Out: Date of consent for marketing email opt-out.
Consent Postal Opt-In: Date of consent for postal opt-in.
Consent Postal Opt-Out: Date of consent for postal opt-out.
Consent Phone Opt-In: Date of consent for phone opt-in.
Consent Phone Opt-Out: Date of consent for phone opt-out.

Generate a detailed insight report for this customer focusing on consent trends and their impact on sales.
"""

insights_list = []

# Generate insights for each customer and store in DataFrame
for _, row in df.iterrows():
    customer_name = row['acc_name']
    
    # Sales insight
    sales_prompt = sales_prompt_template.format(customer_name=customer_name, sales=row[sales_column])
    sales_insight = generate_insight(sales_prompt)
    insights_list.append({'Customer Name': customer_name, 'Category': 'Sales', 'Insight': sales_insight})
    
    # Interaction insight
    interactions = {key: row[key] for key in interaction_columns}
    interaction_prompt = interaction_prompt_template.format(customer_name=customer_name, interactions=interactions)
    interaction_insight = generate_insight(interaction_prompt)
    insights_list.append({'Customer Name': customer_name, 'Category': 'Interaction', 'Insight': interaction_insight})
    
    # Consent insight
    consent = {key: row[key] for key in consent_columns}
    consent_prompt = consent_prompt_template.format(customer_name=customer_name, consent=consent)
    consent_insight = generate_insight(consent_prompt)
    insights_list.append({'Customer Name': customer_name, 'Category': 'Consent', 'Insight': consent_insight})

# Convert insights list to DataFrame
insights_df = pd.DataFrame(insights_list)

# Print insights for review
print(insights_df)



import pandas as pd
from openai import OpenAI

# Load the DataFrame (assuming you have the file path)
file_path = '/mnt/data/your_file.xlsx'  # Update with your actual file path
df = pd.read_excel(file_path)

# Initialize OpenAI agent
llm = OpenAI(api_key="your_openai_api_key")

# Define columns for sales, interaction, and consent
sales_column = 'sales_dec2023'
interaction_columns = [
    'total_interactions_MATQ_growth', 'total_interactions_ROLQ_growth',
    'EVENTS - Veeva_MATQ_growth', 'CALLS - Veeva_MATQ_growth', 
    'AE - Veeva_MATQ_growth', 'SFMC Marketing Email_MATQ_growth'
]
consent_columns = [
    'Consent Approved Email Opt-In', 'Consent Approved Email Opt-Out',
    'Consent Marketing Email Opt-In', 'Consent Marketing Email Opt-Out',
    'Consent Postal Opt-In', 'Consent Postal Opt-Out',
    'Consent Phone Opt-In', 'Consent Phone Opt-Out'
]

# Define prompt templates
sales_prompt_template = """
You are an expert in providing detailed insights.
Our dataset is related to the healthcare industry and contains sales data.
Given a customer with the following sales details:

Customer Name: {customer_name}
Sales for Dec 2023: {sales}

Generate a detailed insight report for this customer focusing on sales trends and any significant changes.
"""

interaction_prompt_template = """
You are an expert in providing detailed insights.
Our dataset is related to the healthcare industry and contains interaction data.
Given a customer with the following interaction details:

Customer Name: {customer_name}
Interaction Data: {interactions}

Generate a detailed insight report for this customer focusing on interaction trends and their impact on sales.
"""

consent_prompt_template = """
You are an expert in providing detailed insights.
Our dataset is related to the healthcare industry and contains consent data.
Given a customer with the following consent details:

Customer Name: {customer_name}
Consent Data: {consent}

Generate a detailed insight report for this customer focusing on consent trends and their impact on sales.
"""

# Function to generate insights using LLM
def generate_insight(prompt):
    response = llm.Completion.create(
        model="text-davinci-003",
        prompt=prompt,
        max_tokens=200
    )
    return response.choices[0].text.strip()

# Initialize an empty DataFrame to store insights
insights_df = pd.DataFrame(columns=['Customer Name', 'Category', 'Insight'])

# Generate insights for each customer and store in DataFrame
for _, row in df.iterrows():
    customer_name = row['acc_name']
    
    # Sales insight
    sales_prompt = sales_prompt_template.format(customer_name=customer_name, sales=row[sales_column])
    sales_insight = generate_insight(sales_prompt)
    insights_df = insights_df.append({'Customer Name': customer_name, 'Category': 'Sales', 'Insight': sales_insight}, ignore_index=True)
    
    # Interaction insight
    interactions = {key: row[key] for key in interaction_columns}
    interaction_prompt = interaction_prompt_template.format(customer_name=customer_name, interactions=interactions)
    interaction_insight = generate_insight(interaction_prompt)
    insights_df = insights_df.append({'Customer Name': customer_name, 'Category': 'Interaction', 'Insight': interaction_insight}, ignore_index=True)
    
    # Consent insight
    consent = {key: row[key] for key in consent_columns}
    consent_prompt = consent_prompt_template.format(customer_name=customer_name, consent=consent)
    consent_insight = generate_insight(consent_prompt)
    insights_df = insights_df.append({'Customer Name': customer_name, 'Category': 'Consent', 'Insight': consent_insight}, ignore_index=True)

# Print insights for review
print(insights_df)

# Optionally, save the insights to a CSV file
insights_df.to_csv('/mnt/data/customer_insights.csv', index=False)
















import pandas as pd
from langchain.llms import OpenAI

# Load the DataFrame (assuming you have the file path)
file_path = '/mnt/data/your_file.xlsx'  # Update with your actual file path
df = pd.read_excel(file_path)

# Initialize OpenAI agent
llm = OpenAI(
    azure_endpoint="https://api-test.mck.com/gpt/libsupport",
    openai_api_version="2022-05-15",
    openai_api_key="Riks79XSYjiewVwoD3be4JN5gS5nRzFA3",
    azure_deployment="gpt-4-32k-0613",
    max_retries=1
)

# Define columns for deltas and other metrics
deltas_columns = ['DeltaRollingQuarterPreviousYearChange', 'DeltaMATChangePY']
sales_column = 'sales_dec2023'
interaction_columns = [
    'total_interactions_MATQ_growth', 'total_interactions_ROLQ_growth',
    'EVENTS - Veeva_MATQ_growth', 'CALLS - Veeva_MATQ_growth', 
    'AE - Veeva_MATQ_growth', 'SFMC Marketing Email_MATQ_growth'
]
consent_columns = [
    'Consent Approved Email Opt-In', 'Consent Approved Email Opt-Out',
    'Consent Marketing Email Opt-In', 'Consent Marketing Email Opt-Out',
    'Consent Postal Opt-In', 'Consent Postal Opt-Out',
    'Consent Phone Opt-In', 'Consent Phone Opt-Out'
]

# Function to categorize customers
def categorize_customers(row):
    delta_rq_change = row['DeltaRollingQuarterPreviousYearChange']
    delta_mat_change = row['DeltaMATChangePY']
    
    if delta_rq_change < 0 and delta_mat_change < 0:
        if delta_rq_change <= -0.2 and delta_mat_change <= -0.2:
            return 'Bad long-term trend continues - Priority 1'
        elif delta_rq_change <= -0.1 and delta_mat_change <= -0.1:
            return 'Bad long-term trend continues - Priority 2'
        else:
            return 'Bad long-term trend continues - Priority 3'
    elif delta_rq_change > 0 and delta_mat_change < 0:
        return 'Bad long-term trend reversal start'
    elif delta_rq_change > 0 and delta_mat_change > 0:
        return 'Bad long-term trend reversal'
    else:
        return 'Other'

# Apply categorization to DataFrame
df['Category'] = df.apply(categorize_customers, axis=1)

# Define the prompt template for generating insights
prompt_template = """
You are the best Data Science and Insights expert in providing detailed insights.
Our dataset is related to the healthcare industry and contains sales data with respect to November and December 2023.
Given a customer with the following details:

Customer Name: {customer_name}
Category: {category}
Sales for Dec 2023: {sales}
Interaction Data: {interactions}
Consent Data: {consent}

Generate a detailed insight report for this customer that includes:
1. Assigned category and priority level.
2. Contextual factors from the data that may contribute to understanding these changes.
3. Insights into how customer interaction and consent status may be influencing sales trends.
4. Label the insight with "Critical Alert" for negative trends or "Positive Highlight" for significant improvements.

Construct a report of approximately 100 words for each customer, delivering insights for only those customers whose changes are most substantial, and remember to exclude customers with marginal or nominal fluctuations.
"""

# Function to generate insights for each customer using LLM
def generate_insights(row):
    customer_name = row['acc_name']
    category = row['Category']
    sales = row[sales_column]
    interactions = {key: row[key] for key in interaction_columns}
    consent = {key: row[key] for key in consent_columns}
    
    # Format the prompt with customer details
    prompt = prompt_template.format(
        customer_name=customer_name,
        category=category,
        sales=sales,
        interactions=interactions,
        consent=consent
    )
    
    # Generate the insight using the LLM agent
    response = llm(prompt)
    return response

# Generate insights for each customer and save to a list
insights = df.apply(generate_insights, axis=1).tolist()

# Print insights for review
for insight in insights:
    print(insight)
    print('-' * 80)

# Optionally, save the insights to a text file
with open('/mnt/data/customer_insights.txt', 'w') as f:
    for insight in insights:
        f.write(insight + '\n')
        f.write('-' * 80 + '\n')














deltas_columns = ['DeltaRollingQuarterPreviousYearChange', 'DeltaMATChangePY']
sales_column = 'sales_dec2023'
interaction_columns = ['total_interactions_MATQ_growth', 'total_interactions_ROLQ_growth']
consent_columns = [
    'Consent Approved Email Opt-In', 'Consent Approved Email Opt-Out',
    'Consent Marketing Email Opt-In', 'Consent Marketing Email Opt-Out',
    'Consent Postal Opt-In', 'Consent Postal Opt-Out'
]

# Function to categorize customers
def categorize_customers(row):
    delta_rq_change = row['DeltaRollingQuarterPreviousYearChange']
    delta_mat_change = row['DeltaMATChangePY']
    
    if delta_rq_change < 0 and delta_mat_change < 0:
        if delta_rq_change <= -0.2 and delta_mat_change <= -0.2:
            return 'Bad long-term trend continues - Priority 1'
        elif delta_rq_change <= -0.1 and delta_mat_change <= -0.1:
            return 'Bad long-term trend continues - Priority 2'
        else:
            return 'Bad long-term trend continues - Priority 3'
    elif delta_rq_change > 0 and delta_mat_change < 0:
        return 'Bad long-term trend reversal start'
    elif delta_rq_change > 0 and delta_mat_change > 0:
        return 'Bad long-term trend reversal'
    else:
        return 'Other'

# Apply categorization to DataFrame
df['Category'] = df.apply(categorize_customers, axis=1)

# Define the prompt template for generating insights
prompt_template = """
You are the best Data Science and Insights expert in providing detailed insights.
Our dataset is related to the healthcare industry and contains sales data with respect to November and December 2023.
Given a customer with the following details:

Customer Name: {customer_name}
Category: {category}
Sales for Dec 2023: {sales}
Interaction Data: {interactions}
Consent Data: {consent}

Generate a detailed insight report for this customer that includes:
1. Assigned category and priority level.
2. Contextual factors from the data that may contribute to understanding these changes.
3. Insights into how customer interaction and consent status may be influencing sales trends.
4. Label the insight with "Critical Alert" for negative trends or "Positive Highlight" for significant improvements.

Construct a report of approximately 100 words for each customer, delivering insights for only those customers whose changes are most substantial, and remember to exclude customers with marginal or nominal fluctuations.
"""

# Function to generate insights for each customer using LLM
def generate_insights(row):
    customer_name = row['customername']
    category = row['Category']
    sales = row[sales_column]
    interactions = {key: row[key] for key in interaction_columns}
    consent = {key: row[key] for key in consent_columns}
    
    # Format the prompt with customer details
    prompt = prompt_template.format(
        customer_name=customer_name,
        category=category,
        sales=sales,
        interactions=interactions,
        consent=consent
    )
    
    # Generate the insight using the LLM agent
    response = llm(prompt)
    return response

# Generate insights for each customer and save to a list
insights = df.apply(generate_insights, axis=1).tolist()

# Print insights for review
for insight in insights:
    print(insight)
    print('-' * 80)

# Optionally, save the insights to a text file
with open('/mnt/data/customer_insights.txt', 'w') as f:
    for insight in insights:
        f.write(insight + '\n')
        f.write('-' * 80 + '\n')

















import pandas as pd
import random
import datetime

# Sample data
data = {
    'InsightID': range(1, 11),
    'AccountID': [random.randint(1, 3) for _ in range(10)],
    'SourceType': ['Sales', 'Interaction', 'Consent', 'YouTube'] * 2 + ['Sales', 'Interaction'],
    'TextData': [
        "Great sales record",
        "Customer was unhappy",
        "Consent for marketing",
        "Positive review on YouTube",
        "Moderate sales record",
        "Client was aggressive",
        "Consent for emails",
        "Negative review on YouTube",
        "Poor sales record",
        "Customer interaction"
    ],
    'InsightType': ['Revenue', 'Feedback', 'Marketing', 'Review'] * 2 + ['Revenue', 'Feedback'],
    'CollectedOn': [datetime.date(2024, 1, random.randint(1, 31)) for _ in range(10)],
    'JobRole': ['Manager', 'Analyst', 'Marketer'] * 3 + ['Manager'],
    'InsightMonth': [1, 1, 1, 1, 2, 2, 2, 2, 1, 1]
}

# Create DataFrame
df = pd.DataFrame(data)



from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI

class CombinedInsights(BaseModel):
    combined_insights: str = Field(description="Combined insights")

# Define the prompt template
combined_prompt = ChatPromptTemplate.from_template(
    """
Given the following insights from sales, consents, interactions, and YouTube, provide a combined analysis.

Insights:
{input}
"""
)

# Initialize the model
llm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo-0125").with_structured_output(CombinedInsights)

# Create a chain for combining insights
combined_chain = combined_prompt | llm

# Function to fetch and combine insights for a particular month and job role
def fetch_combined_insights(df, insight_month, job_role):
    # Filter DataFrame based on conditions
    filtered_df = df[(df['InsightMonth'] == insight_month) & (df['JobRole'] == job_role)]
    insights_text = "\n".join(filtered_df['TextData'].tolist())
    
    # Get combined insights from the chain
    result = combined_chain.invoke({"input": insights_text})
    combined_insights = result['structured_output']['combined_insights']
    return combined_insights

# Example usage
combined_analysis = fetch_combined_insights(df, insight_month=1, job_role='Manager')
print(combined_analysis)














import pandas as pd
from youtube_transcript_api import YouTubeTranscriptApi

# Load the Excel file
df = pd.read_excel('/mnt/data/video_links.xlsx')

def get_transcript_and_language(video_url):
    video_id = video_url.split('watch?v=')[1]
    try:
        # Get a list of available transcripts
        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
        
        # Fetch the first available transcript (regardless of language)
        transcript = transcript_list.find_generated_transcript(['de', 'en'])
        
        # Get the transcript in its original language
        transcript_data = transcript.fetch()
        language = transcript.language_code
        
        # Join all text elements in the transcript
        transcript_text = ' '.join([t['text'] for t in transcript_data])
        return transcript_text, language
    except Exception as e:
        print(f"An error occurred: {e}")
        # Return None for both transcript and language if there's an error
        return None, None

# Apply the function to all rows in the DataFrame for the 'Youtubelinks' column
df[['Transcript', 'Language']] = df['Youtubelinks'].apply(
    lambda url: pd.Series(get_transcript_and_language(url))
)

# Save the updated DataFrame back to a new Excel file
df.to_excel('/mnt/data/video_links_with_transcripts.xlsx', index=False)











import pandas as pd
from youtube_transcript_api import YouTubeTranscriptApi
import os

# Directory to save transcript files
transcript_dir = '/mnt/data/transcripts'
if not os.path.exists(transcript_dir):
    os.makedirs(transcript_dir)

def save_transcript_to_file(video_url):
    video_id = video_url.split('watch?v=')[1]
    transcript_filename = f"transcript_{video_id}.txt"
    transcript_filepath = os.path.join(transcript_dir, transcript_filename)
    try:
        transcript_list = YouTubeTranscriptApi.get_transcript(video_id)
        transcript_text = ' '.join([item['text'] for item in transcript_list])
        
        with open(transcript_filepath, 'w', encoding='utf-8') as file:
            file.write(transcript_text)
        
        # Return the path to the transcript file
        return transcript_filepath
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

# Load video URLs from Excel
df = pd.read_excel('video_links.xlsx')

# Apply the function to save transcripts to files and store the file paths in a new column
df['transcript_file'] = df['Youtubelinks'].apply(save_transcript_to_file)

# Save the updated DataFrame back to Excel
df.to_excel('video_links_with_transcript_files.xlsx', index=False)







import pandas as pd
from youtube_transcript_api import YouTubeTranscriptApi

# Load the Excel file
df = pd.read_excel('/mnt/data/image.png')

# Define a function to get the transcript
def get_transcript(video_url):
    video_id = video_url.split('watch?v=')[1]
    try:
        transcript = YouTubeTranscriptApi.get_transcript(video_id)
        # Join all text elements in the transcript
        return ' '.join([t['text'] for t in transcript])
    except:
        # Return an empty string if there's an error (video may not have transcripts available)
        return ''

# Apply the function to all rows in the DataFrame for the 'Youtubelinks' column
df['Transcript'] = df['Youtubelinks'].apply(get_transcript)

# Save the updated DataFrame back to a new Excel file
df.to_excel('/mnt/data/updated_transcripts.xlsx', index=False)















Analyze the sales data focusing on the 'Retail' customer type and identify the top 15 customers based on MAT (Moving Annual Total) growth in December 2023. For each of these top customers, calculate the delta in RollingQuarter and MAT between November and December, considering DeltaRollingQuarterPreviousYearChange and DeltaMATCHangePY. Also, take into account the 'total_interactions' and 'Days_LastF2Fcall' as indicators of customer engagement and consent data to gauge communication permissions.

Categorize these customers into the following groups based on the magnitude of these deltas, while also considering the context provided by the interaction and consent data:

1. 'Bad long-term trend continues' - Then further classify these customers into:
   - Priority 1: Both Delta RollingQuarterPreviousYearChange and Delta MATCHangePY show a decrease by more than 20%. Consider the 'total_interactions' and consent columns to assess if low engagement or consent issues might be contributing factors.
   - Priority 2: Both Delta RollingQuarterPreviousYearChange and Delta MATCHangePY show a decrease by 10-20%. Review 'total_interactions' and the recency of 'Days_LastF2Fcall' to understand if efforts to re-engage have been made or consent limitations exist.
   - Priority 3: Both Delta RollingQuarterPreviousYearChange and Delta MATCHangePY show a decrease by less than 10%. Evaluate if there's a correlation between interaction frequency, consent status, and the lesser decrease in sales metrics.

2. 'Bad long-term trend reversal start' - For customers with a positive Delta RollingQuarterPreviousYearChange but a negative Delta MATCHangePY. Assess if improved interactions or recent consent changes may be influencing this reversal.

3. 'Bad long-term trend reversal' - For customers showing positive changes in both Delta RollingQuarterPreviousYearChange and Delta MATCHangePY. Acknowledge if increased interactions and positive consent status align with these improvements.

Provide a report that includes:

- Customer's name.
- Customer's type.
- Delta RollingQuarterPreviousYearChange.
- Delta MATCHangePY.
- Total interactions.
- Days since the last face-to-face call.
- Consent status across all channels.
- Assigned category and priority level.

The report should give insight into how customer engagement and consent status may be influencing sales trends. Include only customers whose delta changes are significant as per the criteria and who rank in the top 15 by MAT growth.










Perform a detailed analysis of the sales data to calculate the delta in RollingQuarter and MAT between November and December for each customer. Based on the magnitude of these deltas, categorize customers into the following groups:

1. 'Bad long-term trend continues' - Then further classify these customers into:
   - Priority 1: Both Delta RollingQuarter and Delta MAT decrease by more than 20%.
   - Priority 2: Both Delta RollingQuarter and Delta MAT decrease by 10-20%.
   - Priority 3: Both Delta RollingQuarter and Delta MAT decrease by less than 10%.

2. 'Bad long-term trend reversal start' - For customers with a positive Delta RollingQuarter but a negative Delta MAT.

3. 'Bad long-term trend reversal' - For customers showing positive changes in both Delta RollingQuarter and Delta MAT.

For each category, sort customers by the magnitude of their deltas and include the following in your report:

- Customer's name.
- Calculated Delta RollingQuarter.
- Calculated Delta MAT.
- Assigned category and priority level based on the deltas.

Ensure that the report focuses on these specified categories and priorities, and excludes customers not meeting the criteria of having significant deltas.




Analyze the sales data to calculate the delta in RollingQuarter and MAT between November and December for each customer. Use these deltas to categorize customers into the following groups as per the changes observed:

1. 'Bad long-term trend continues' for customers who have a Negative change in both Delta RollingQuarter and Delta MAT.
2. 'Bad long-term trend reversal start' for customers who show a Positive change in Delta RollingQuarter but still a Negative change in Delta MAT.
3. 'Bad long-term trend reversal' for customers who show a Positive change in both Delta RollingQuarter and Delta MAT.

Present the findings in a report that lists only the customers falling into these categories. The report should include:

- The customer's name.
- The calculated Delta RollingQuarter.
- The calculated Delta MAT.
- The category each customer falls into based on their deltas.

Exclude all customers who do not fall into any of these categories to ensure the report is concise and focused on the customers of interest as per the specified criteria.










Analyze the sales data for each customer with a focus on the following metrics: sales_dec2023, PreviousYearChange, RollingQuarterChange, YTDChange, MATCHange, and PreviousMonthChange. Identify customers with considerable shifts between November and December 2023 and provide insights only for those with the most significant changes as per these conditions:

1. An increase or decrease in `PreviousMonthChange` by more than 50%.
2. A `MATCHange` of greater than 30% in either direction, which could indicate a significant trend.
3. A `YTDChange` or `PreviousYearChange` of more than 30%, reflecting major shifts over a longer period.
4. Customers with a `RollingQuarterChange` greater than 20% suggesting notable quarterly performance.

For each customer meeting any of the above criteria, articulate a precise insight that includes:

- A comparison of their sales performance changes between November and December 2023.
- Contextual factors from the data that may contribute to understanding these changes.
- Label the insight with "Critical Alert" for negative trends or "Positive Highlight" for significant improvements.

Construct a report of approximately 500 words, delivering insights for only those customers whose changes are most substantial, excluding customers with marginal or nominal fluctuations.









Analyze the provided sales data with columns: emp_name, customernameh2, sales_dec2023, previous_month_change, PreviousYearChange, RollingQuarter, RollingQuarterPreviousYearChange, YTD, YTDChangeP, MAT, MATChangeP. Construct a 500-word report detailing:

1. A ranked summary of each employee's sales performance, focusing on changes observed in previous_month_change, YTD, and MATChangeP, specifically highlighting any significant shifts or anomalies.
2. A trend analysis of sales_dec2023 against previous_month_change, illustrating any patterns, and comparing these trends to the PreviousYearChange and RollingQuarter metrics.
3. A review of customer sales performance, indicating which customers have shown the most significant changes in sales_dec2023 and previous_month_change, along with a discussion on the stability or volatility in their purchasing patterns.
4. An exploration of the data to reveal any potential correlations between RollingQuarter and RollingQuarterPreviousYearChange across different customer segments.
Please ensure that the report includes factual insights derived from the data, emphasizing notable findings, and refrains from making unfounded predictions or recommendations.



Using the sales data columns: emp_name, customernameh2, sales_dec2023, previous_month_change, PreviousYearChange, RollingQuarter, RollingQuarterPreviousYearChange, YTD, YTDChangeP, MAT, MATChangeP, analyze the sales performance for the employee named '{employee_name}'. Prepare a 500-word report that provides:

1. An in-depth review of the employee's sales figures, particularly focusing on sales_dec2023 and previous_month_change, highlighting any major increases or decreases.
2. A comparative analysis of the employee's current YTD sales figures with the previous year's performance, using PreviousYearChange as a key indicator.
3. An assessment of the monthly and quarterly sales progression for the employee's customer portfolio, utilizing the RollingQuarter and previous_month_change to identify any trends.
4. An overview of the long-term sales pattern reflected by MAT and MATChangeP, discussing consistency and identifying any outlier months or quarters.
This report should be grounded in the data provided, accentuating noteworthy trends and patterns specific to the employee's sales activity without the inclusion of prospective advice or conjecture.










def create_employee_prompt(employee_name):
    return f"""
    Analyze sales performance using the dataset with columns emp_name, customernameh2, sales_dec2023, 
    PreviousYearChange, RollingQuarter, RollingQuarterPreviousYearChange, YTD, YTDChangeP, MAT, MATChangeP, 
    focusing on the data related to the employee named '{employee_name}'. Create a report that includes:
    
    1. An overview of sales performance with an emphasis on sales_dec2023 and YTD, highlighting successes 
       and areas for customer engagement improvement.
    2. An analysis of PreviousYearChange for each managed customer, identifying significant growth or decline.
    3. A review of RollingQuarter and RollingQuarterPreviousYearChange data to uncover quarterly trends 
       or anomalies in the sales territory.
    4. Insights into long-term sales trajectory and customer loyalty, considering MAT and MATChangeP.
    5. Recommendations for strategies to improve sales with underperforming customers and maintain/enhance 
       sales with top-performing customers.
       
    Please ensure the insights are concise, providing clear guidance for future sales strategies.
    """








SM
Please analyze the provided sales data with the following headers: emp_name, customernameh2, sales_dec2023, PreviousYearChange, RollingQuarter, RollingQuarterPreviousYearChange, YTD, YTDChangeP, MAT, MATChangeP. Generate a comprehensive report that includes:

1. A summary of sales performance for each employee. Identify top performers based on YTD sales and note any concerning trends in MATChangeP.
2. Assess overall sales trends, focusing on YTDChangeP and MATChangeP, to identify any potential seasonal impacts or market shifts.
3. Evaluate customer sales performance. For customers with a sales_dec2023 greater than the average, discuss growth potential. For those below, provide strategies to improve sales.
4. Examine the PreviousYearChange and RollingQuarterPreviousYearChange metrics to pinpoint any significant deviations and what they might suggest about market dynamics.
5. Present this analysis with actionable insights, noting areas of success and recommending targeted strategies for areas that show a decline or slower growth. Include visual representations such as graphs or charts where possible for easier comprehension.


SR
Analyze my sales performance using the data provided with columns: emp_name, customernameh2, sales_dec2023, PreviousYearChange, RollingQuarter, RollingQuarterPreviousYearChange, YTD, YTDChangeP, MAT, MATChangeP. Focus on my customers and sales figures, and create a report that includes:

1. An overview of my sales performance, using sales_dec2023 and YTD to highlight my successes and customers that may need more attention.
2. Analyze the change in sales from the previous year (PreviousYearChange) for each customer I manage, identifying those with significant growth or decline.
3. Review the RollingQuarter and RollingQuarterPreviousYearChange data to determine if there are any quarterly trends or anomalies specific to my sales territory.
4. Discuss my performance in the context of MAT and MATChangeP, providing insight into the long-term sales trajectory and customer loyalty.
5. Offer recommendations for improving sales with underperforming customers and strategies to maintain or enhance sales with top-performing customers.
Please ensure the insights are concise and provide clear guidance for sales strategies moving forward.









SR
Conduct a targeted analysis of my sales performance using the dataset containing columns for employee name, customer name, sales for December 2023, sales for the previous year, rolling quarter sales, previous year change, rolling quarter previous year change, YTD, YTD change percentage, MAT, and MAT change percentage. Generate a report that covers:

1. My total sales in December 2023 and a comparison to the previous year’s sales figures.
2. Identify my top three customers in terms of sales growth from December 2022 to December 2023.
3. Assess the trends in my rolling quarter sales compared to the same quarter in the previous year, highlighting any substantial increases or decreases.
4. Calculate my YTD sales and the change percentage, discussing how this aligns with my annual sales targets.
5. Analyze my MAT sales figures to understand my performance stability over time.
6. Based on the analysis, provide recommendations for improving my sales with specific customers and strategies for potentially expanding my customer base.


SM
Analyze the sales dataset with columns for employee name, customer name, sales for December 2023, sales for the previous year, rolling quarter sales, previous year change, rolling quarter previous year change, YTD, YTD change percentage, MAT, and MAT change percentage. Provide a comprehensive report that includes the following analyses:

1. Summarize total sales in December 2023 for each employee, identifying the highest and lowest performers.
2. Determine the year-over-year growth in sales by comparing December 2023 figures to the previous year's sales, providing a ranked list of customers by the percentage increase.
3. Examine rolling quarter sales and the percentage change from the previous year for each customer, highlighting any that show significant variances.
4. Analyze the Year-To-Date (YTD) sales figures and the YTD change percentage to pinpoint trends and project the potential end-of-year outcomes.
5. Evaluate the Moving Annual Total (MAT) sales and the percentage change for insight into long-term trends.
6. Offer strategic insights based on the sales data, suggesting focus areas for the next quarter and potential risk mitigation for underperforming areas.




import ipywidgets as widgets
from IPython.display import display, clear_output

# Placeholder function for analysis
# You should replace the contents of this function with the actual analysis code
def perform_analysis(prompt):
    # Here you would have the code that performs the analysis
    # This could involve sending the prompt to an external API or running a local analysis
    print("Analyzing with prompt:")
    print(prompt)
    # Imagine analysis happens here, and we print "Analysis Complete" when done
    print("Analysis Complete\n\n")

# Generate the report based on the role and the employee name
def generate_report(role, employee_name=''):
    if role == 'Sales Manager':
        prompt = """
        Please analyze the attached CSV file containing sales data and provide a detailed report that includes:
        1. Overall sales performance by each employee, highlighting top performers.
        2. Trends over the past year, identifying seasonal patterns or notable fluctuations.
        3. Customer sales performance, focusing on growth, churn, and opportunities for upselling.
        4. Correlations between sales activities and performance outcomes.
        Provide charts and graphs for visual data representation where applicable.
        """
    else:
        prompt = f"""
        Please analyze the attached CSV file focusing on the sales data for the employee named '{employee_name}'. 
        Provide a report that includes:
        1. A summary of my sales performance with my assigned customers.
        2. Trends and forecasted performance over the next quarter.
        3. My top three customers in terms of sales growth.
        4. Recommendations for sales strategies to improve performance.
        Ensure the report is personalized and actionable.
        """

    # Run the analysis
    perform_analysis(prompt)

# Widgets for user input
role_dropdown = widgets.Dropdown(
    options=['Employee', 'Sales Manager'],
    value='Sales Manager',
    description='Role:',
)

employee_name_text = widgets.Text(
    value='',
    description='Name:',
)

generate_button = widgets.Button(
    description='Generate Report',
    button_style='success',
)

output_area = widgets.Output()

# Event to handle button click
def on_generate_button_clicked(b):
    role = role_dropdown.value
    employee_name = employee_name_text.value
    with output_area:
        clear_output()
        if role == 'Employee' and not employee_name:
            print("Please enter the employee name.")
        else:
            generate_report(role, employee_name)

# Attach the event handler to the button
generate_button.on_click(on_generate_button_clicked)

# Display the UI components
display(role_dropdown, employee_name_text, generate_button, output_area)


To get advanced analysis insights for the customers with respect to the sales metrics from the given CSV file, you would want to consider a prompt that specifically asks for the kind of analysis you're interested in. Here's a prompt that could work for the LangChain CSV agent:

"Given a CSV file with the following headers: customer name, sales for December 2023, sales for the previous year, rolling quarter sales, rolling quarter sales for the previous year, year-to-date sales change percentage, and moving annual total sales change percentage:

Calculate the year-over-year growth rate for December sales.
Identify the top 5 customers with the highest sales in December 2023.
Compare the rolling quarter sales to the previous year's rolling quarter sales and highlight significant trends or changes.
Analyze the year-to-date sales change percentage to identify any seasonal patterns or anomalies.
Evaluate the moving annual total sales change percentage for insights into long-term customer value and loyalty.
Provide visualizations such as line graphs or bar charts that represent the sales trends and comparisons over time.
Suggest strategic recommendations for the customers with declining sales and opportunities for upselling to those with growing sales.
Please output the analysis in a summarized report format that includes the calculations, visual representations, and strategic insights."







system_prompt = 'I want you to act as a professional in making good summaries from youtube videos!'
prompt = f'''Break the text to be processed into chunks if needed in interest of tokens and process
Summarize the following text in {language_code}.
    Text: {texts}

    Add a title to the summary in {language_code}.
    Include an INTRODUCTION, BULLET POINTS if possible, and a CONCLUSION in {language_code}.'''


    # Start summarizing using OpenAI
response = openai.chat.completions.create(
        model=model_name,
        messages=[
            {'role': 'system', 'content': system_prompt},
            {'role': 'user', 'content': prompt}
        ],
        temperature=1
    )
prompt1 = f'''Share the {response.choices[0].message.content} in english'''
response1 = openai.chat.completions.create(
        model=model_name,
        messages=[
            {'role': 'user', 'content': prompt1}
        ],
        temperature=1
    )
print(response1.choices[0].message.content)






https://python.langchain.com/docs/guides/evaluation/

https://langfuse.com/guides/cookbook/integration_azure_openai_langchain

https://blog.langchain.dev/benchmarking-question-answering-over-csv-data/
https://www.youtube.com/watch?v=jGnf4OhptbA

20-Day Plan for GENAI LangChain-based Product Development
Day 1: Define project scope and objectives for the GENAI LangChain-based solution.
Day 2: Identify and document specific use cases and requirements for target user roles.
Day 3: Set up the development environment and install necessary LangChain and GENAI libraries.
Day 4: Develop a preliminary data schema for handling sales and interaction data.
Day 5: Write initial scripts for data ingestion and preprocessing from existing databases.
Day 6: Create a basic structure for the LangChain application, focusing on data handling.
Day 7: Develop initial conversational flows for the GENAI model based on role-specific scenarios.
Day 8: Implement a logging system for tracking user queries and model responses.
Day 9: Integrate the first conversational flow into the LangChain application.
Day 10: Conduct internal testing of the initial conversational flow for functionality and coherence.
Day 11: Refine conversational flows based on internal feedback and test results.
Day 12: Develop additional conversational flows for different user roles and scenarios.
Day 13: Implement an interface for users to interact with the GENAI LangChain model.
Day 14: Set up basic analytics for monitoring user interactions and model performance.
Day 15: Conduct a comprehensive review of all conversational flows and user interfaces.
Day 16: Develop documentation for internal users to guide them in using the system.
Day 17: Begin integration of external APIs for real-time data updates if applicable.
Day 18: Conduct extensive internal testing with a focus on edge cases and error handling.
Day 19: Collect and analyze feedback from internal testing; make necessary adjustments.
Day 20: Plan for external pilot testing, including participant selection and feedback mechanisms.










Title: How Hepatitis E and HPV Can Affect Life - Understand and Prevent

Introduction:
In this summary of the YouTube video, we will cover two distinct medical issues - Hepatitis E and the Human Papillomavirus (HPV). Hepatitis E is a liver inflammation caused by ingesting contaminated meat and water, while HPV, a sexually transmitted infection, can cause cervical cancer. Both diseases involve mechanisms for prevention, diagnosis, and treatment.

Main Points:
- Hepatitis E is a zoonotic disease, a disease transferred from animals to humans. Acute symptoms can include jaundice, diarrhea, and vomiting. People with weakened immune systems can have chronic illness.
- Preventing Hepatitis E involves cooking meats for a minimum of 20 minutes at temperatures exceeding 71 degrees and maintaining good hygiene.
- It is advised that young women have regular cervical cancer screenings (Pap Test) from the age of 21 onwards. If results are normal, the test is only necessary every three years.
- In addition to the Pap smear, there is a HPV-PCR test, which can detect the presence of HPV viruses in the sample. However, this test is not yet covered by health insurance in Switzerland.
- An HPV vaccine is recommended before a person becomes sexually active. In Switzerland, the costs for the vaccine are fully covered between the ages of 11 and 26.

Conclusion: 
While Hepatitis E and HPV pose different health problems, prevention and early detection play crucial roles for both diseases. Suitable treatments contribute to improving the quality of life of affected individuals. People who demonstrate risk factors or live in areas with high infection risk should be aware of these available preventive measures and treatment options.
























The video discusses the case of Bernhard Runker, who developed severe pain due to Hepatitis E, a liver inflammation transmitted from animals to humans, diagnosed at the University Clinic in Basel. Key points include the transmission of Hepatitis E through contaminated water and undercooked meat, Bernhard's treatment involving medications and therapy leading to recovery, and preventive measures like proper food handling and hygiene to avoid the virus. Despite Hepatitis E being rare in Switzerland, awareness and prompt medical intervention for symptoms are emphasized.


Introduction: 
This video is about Bernhard Runker, who began to struggle with severe pain in his shoulders, chest, arms, and hands five years ago. Tests at the University Clinic in Basel led to a diagnosis of Hepatitis E, a form of hepatitis that is transmitted from animals to humans. 

Main Ideas:

- Hepatitis E is a form of hepatitis, an inflammation of the liver, which is transmitted from animals to humans. It is different from other types of hepatitis in this regard.
- Most people with Hepatitis E notice nothing, while some, like Bernhard, suffer from severe pain and discomfort.
- Hepatitis E can be transmitted through contaminated water and meat products. It is particularly important to thoroughly cook meat in order to inactivate the virus.
- Bernhard received strong medications and cortisone for the pain. He also began physio and occupational therapy to stimulate the nerves in the affected body parts.
- After several months of treatment, the feeling returned to his fingers and he was able to use his hand normally again.
- It is still unclear how Bernhard contracted the virus. To avoid a recurrence, he is now very careful about what he eats.

Conclusion:
Although Hepatitis E is not very common in Switzerland, it's important to know how the virus is transmitted in order to protect oneself. This includes thoroughly cooking meat and practicing proper hygiene. Individuals who experience severe pain or other symptoms should seek medical attention immediately. 

Title: Bernhard's Battle Against Hepatitis E: A Path to Recovery


https://docs.google.com/presentation/d/1o0NVoEDpvN-BuLCXRrBnWt5W3DYw3SVw/edit?usp=sharing&ouid=115761606175286406693&rtpof=true&sd=true

import pandas as pd
import sqlite3

# Load CSV files into pandas DataFrames
df1 = pd.read_csv('file1.csv')
df2 = pd.read_csv('file2.csv')

# Create a SQLite database
conn = sqlite3.connect('example.db')

# Convert the DataFrames to SQL tables
df1.to_sql('table1', conn, if_exists='replace', index=False)
df2.to_sql('table2', conn, if_exists='replace', index=False)

# Close the connection to the database
conn.close()



These definitions are based on common terms used in pharmaceutical sales and CRM (Customer Relationship Management) systems:

pk_mdm_key: Primary key or unique identifier used in the Master Data Management (MDM) system to uniquely identify records.

customer_territory_name: Name or identifier of the geographic or organizational territory assigned to a customer.

customer_target: The sales or engagement target set for a customer or a group of customers.

emp_name: Name of the employee, typically referring to the sales representative or account manager.

emp_department: Department within the organization to which the employee belongs.

customer_bu: Customer's business unit, referring to the specific division or sector of the customer's organization.

customer_franchise: The franchise or product line that the customer is associated with within the pharmaceutical company's offerings.

customer_bu_code: A unique code or identifier for the customer's business unit.

customer_franchise_code: A unique code or identifier for the customer's franchise.

int_channel: The channel through which an interaction with a customer was conducted (e.g., phone, email, face-to-face).

int_type: Type of interaction (e.g., sales call, service request, feedback).

int_subtype: More specific categorization of the interaction type (e.g., initial contact, follow-up, complaint).

taxonomy_key: A categorization key that helps in classifying the interaction based on predefined taxonomy (e.g., product inquiry, service issue).

int_title: Title or subject of the interaction.

event_participant_role: Role of the participant in the interaction (e.g., decision-maker, influencer, user).

contact_mdm_id: Unique identifier for the contact in the Master Data Management system.

case_prod_key: Key or identifier linking the interaction or case to a specific product.

key_description: Description associated with the case_prod_key, providing details about the product or case.

cases_date: Date of the interaction or case creation.

int_rejection: Indicator or details regarding whether the interaction was rejected by the customer.

int_acceptation: Indicator or details regarding whether the interaction was accepted by the customer.

int_reaction: Customer's reaction or response to the interaction.

total_opens: Total number of times the customer opened an email or document related to the interaction.

total_actions: Total actions taken by the customer as a result of the interaction.

planned_call_flag: Indicator whether the interaction was a planned call or meeting.

ean: European Article Number, which might be used here as a unique identifier for products.

units: Quantity of products discussed or sold during the interaction.

sales: Revenue or sales amount associated with the interaction or transaction.

sales_channel: The sales channel through which the product was sold or the interaction occurred (e.g., direct, online, distributor).

country_code: Country code representing the geographical location associated with the interaction or sales transaction.

https://medium.com/@c.giancaterino/langchain-openai-in-action-with-different-data-sources-e089ca43c90a

brand_name: Name of the product brand involved in the interaction or sales.

mdm_key: Another unique identifier used within the Master Data Management system, possibly linking different tables or records.

customernameh2: Possibly a secondary customer name or an alternative identifier for the customer.




from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitters import CharacterTextSplitter

# This function replaces CVStoVectorStoreIndex
def CSVtoFAISSIndex(dataframe):
    # Convert DataFrame to a list of documents (assuming each row is a document)
    documents = dataframe.to_dict('records')  # Convert each row to a dictionary

    # Initialize OpenAI embeddings (ensure your OPENAI_API_KEY is set)
    embeddings = OpenAIEmbeddings()

    # Split documents into chunks if they are too large (optional, adjust based on your needs)
    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
    docs = text_splitter.split_documents(documents)

    # Create FAISS index from documents
    vectorstore = FAISS.from_documents(docs, embeddings)

    return vectorstore


def main():
    # Create a log directory if it doesn't exist
    log_directory = "logs"
    if not os.path.exists(log_directory):
        os.makedirs(log_directory)
    
    # Configure logging
    log_filename = datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + '.log'
    log_filepath = os.path.join(log_directory, log_filename)
    logging.basicConfig(
        filename=log_filepath,
        filemode='a',
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        level=logging.DEBUG
    )

# Initialize variables for email content
email_subject = f"Summary of Insights for {role} in {industry}"
email_body_intro = f"""
Hi Team,

Please find below the summary of insights we've gathered based on the recent analysis for the role of {role} in the {industry} industry.

"""

# Start with the introduction for the email body content
email_body_content = email_body_intro

# Loop through each question and answer
for i, k in enumerate(list_from_string):
    # Assuming this method synchronously returns the answer as a string
    answer = gpt4_agent.run(k)  
    # Print question and answer in the Streamlit app
    st.markdown(
        f"<div class='slack-container'><div class='slack-question'>Question {i + 1}: {k}</div><div class='slack-answer'>{answer}</div></div>",
        unsafe_allow_html=True,
    )
    # Append question and answer to the email body content
    email_body_content += f"Question {i + 1}: {k}\nAnswer: {answer}\n\n"

# Wrap up the email with a closing
email_body_content += "Best regards,\n[Your Name]\n"

# Display the email format in the app
st.subheader("Email Format Summary")
st.text_area("Email Subject", email_subject, height=50)
st.text_area("Email Body", email_body_content, height=400)
